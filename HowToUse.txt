Simple Rendering tool, version 0.1 ?

-------------------------

How to set up :
Make 3 new folders for your project. One in rawdata folder, one in object, and one in result.
You may want to give them all the same name for the sake of simplicity (ex. goto01).
Put all your raw vtk data, both points and volumetric, into the new raw data folder that your just made (ex. ~/rawdata/goto01).

-------------------------

How to use :
1. Use Python tools provided to either
    a) Extract isosurface from volumetric data, creating 3d models
    b) Transform point data in vtk into numpyarray
    The resulting models/npy should be stored in object folder (ex. object/goto01)

2. Adjust the image size at the main.cpp, then compile it with
    g++ -std=c++11 -fopenmp main.cpp
    You should get a a.out executable out of it. This iamge size is probably the only part that we need to recompile after adjustments.

3. Goto SetupConfig and adjust the setting of those txt files as you see fit. Each file represents different parts of the configuration.
    ***
    Better presume that all of these configuable parameters are case sensitive, order sensitive, and space sensitive.
    Look at Example files well and try to conform to them as close as possible
    For any questions, you can always ask Aomsin directly :)
    ***
    IOSetup.txt : Used to set up file IO
        have OutputName: , StartingIndex: , EndingIndex: 
        Each is used to set the rendered image name, the number of files to start and to end (in case of a video rendering)

    LightsSetup.txt : Used to set up light objects in the world and background color
        have LightMats: , LightGeo: , BackgroundColor:
        LightMats is used to set up strength of each light source 

            ex. diff,a,b,c here, a b c represents red green blue component of the light respectively (just ignore diff for now)

            ***
            If you have more than one lights, please set the value of red component a little bit different between them.
            This is a bug that Aomsin is trying to address at the moment. For now, different red value will have to work.
            ***

        LightGeo is used to set up geometric representation of the light source
            Since we only support rectangular light at the moment (in the case of multiple importance sampling,
            you can use what ever kind of light if you are going with native tracing option), this means what kind of rectangular we made.

            ex. yz,1,3,0,2,4 means a rectangle in yz plane. Ranging from y = 1 to 3 and z = 0 to 2, with x = 4

            Be sure to allign the Mats and Geo well, since the order of Mats will be the same order assigned to each Geometry.

        BackgroundColor is used to set the background color in the scence. Each component represents red green and blue component of light.

    LookFrom.txt : Used to set up things such as what direction is the top of the image, from where to look, to look at where, 
    and how many samples ought to be taken for each pixel in the image.

    ModelsSetup.txt : Used to set up models to be rendered
        CombinationType:
            you can choose between these 3, depending on the type of scence you want to visualizer
                IsoSurface : For scence with only isosurface (thus only obj)
                Spheres : For scence with only Spheres (thus only npy)
                IsoSurfaceAndSphere : For scence with both types of data mixing together
        
        OBJModelMats:
            Specify the material that you want, you have the following 3 choices
                lam,a,b,c : Lambertian material with rgb = abc
                beer,a,b,c,d,e : Beer-Lambert material (transparent) with index_of_refraction = a, density = b, rgb = cde 
                met,a,b,c,d : Metal with fuzz (how imperfect the surface is) = a, rgb = bcd
        
        OBJModelName:
            Name of the model that we will use. Similar to light, beware of the order between your models and materials.

        The same setting process could also be done for the SphereModel.
        ***
        However, beware that we need to specify the radian and number too in the case of SphereModel.
        This is an artifact effect from Sakaguchi's method of writing data. It will probably be fixed at some point ?
        ***
        
        Finally, we can also put rectangular walls here using,
            WallMats:
            WallsGeo:
        
    YesOrNo.txt : Used to answer some yes/no sort of questions, you shoud only choose "true" or "false" for each setting in this file
        TrsutNormal: Whether to trust the normal data of the model or not (a lot of models have unreliable normals that we better ignored)

        Naive: Whether to use naive tracer or multiple-importance-sampling tracer. Turn this on will give higher quality image in general, 
        but we need at least one light source in the LightsSetup segment for the algorithm to work.

        HasLights: If turn off, all light in the LightsSetup will be ignored (Thus the multiple-importance-sampling will also not work obviously).
        We could use it to quickly test things without the need to write the whole light setting from 0 everytime we switch back and forth.

        DynamicLight: To use dynamic background or not. If turned on, the BackgroundColor will be ignored and dynamic background used instead.

4. Run the code with 
    
    ./a.out x

    Here, x is the amount of multithred that we want to use for the rendering. 
    In case of Goto Lab's PC 6 is usually the magic number, but for larger machine like supercomputer, the number may go up to 30~50.

-------------------------
            